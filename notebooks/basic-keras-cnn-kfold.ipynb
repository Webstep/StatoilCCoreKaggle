{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building CNN using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.layers import Conv2D # spatial convolution over images\n",
    "from keras.layers import MaxPooling2D # operation for spatial data\n",
    "from keras.layers import Dense # densely-connected NN layer\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Nadam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Local imports\n",
    "import adjust_path  # Before doing any local imports\n",
    "from icc.data_loader import DataLoader\n",
    "from icc.contrib.preprocessing.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augmented = False\n",
    "if train_augmented:\n",
    "    # Load augmented data\n",
    "    with open('../data/train_augmented.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    X = data[['band_1','band_2']]\n",
    "    y = data['is_iceberg']\n",
    "else:\n",
    "    X, y = DataLoader.load_train()\n",
    "\n",
    "print(\"{} samples in X and y\".format(len(X)))\n",
    "X.inc_angle = X.inc_angle.replace('na',0)\n",
    "idx_tr = np.where(X.inc_angle>0) # about 1471 images greater than angle 0\n",
    "\n",
    "# Actual training of the network\n",
    "\n",
    "# Preprocessing step\n",
    "prep = Preprocess()\n",
    "x_train, x_valid, y_train, y_valid = prep._basic_trainset(X, y, how='deep', test_size=0.0)\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "#y_onehot_train= to_categorical(y_train, num_classes=2)\n",
    "#y_onehot_valid= to_categorical(y_valid, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[idx_tr[0]]\n",
    "x_train = x_train[idx_tr[0],...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "\n",
    "    # Start by defining a Sequential model.\n",
    "    model = Sequential()\n",
    "\n",
    "    # Next add layers via the `.add()` method\n",
    "\n",
    "    # Conv Layer 1\n",
    "    model.add(Conv2D(filters=64, \n",
    "                     kernel_size=(3, 3), \n",
    "                     strides=(1, 1), \n",
    "                     padding=\"valid\", \n",
    "                     input_shape=(75, 75, 3))) # change from rgb to gray scale\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "    # Conv Layer 2\n",
    "    model.add(Conv2D(filters=128, \n",
    "                     kernel_size=(3, 3), \n",
    "                     strides=(1, 1), \n",
    "                     padding=\"valid\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Conv Layer 2\n",
    "    model.add(Conv2D(filters=128, \n",
    "                     kernel_size=(3, 3), \n",
    "                     strides=(1, 1), \n",
    "                     padding=\"valid\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "    # Conv Layer 4\n",
    "    model.add(Conv2D(filters=256, \n",
    "                     kernel_size=(3, 3), \n",
    "                     strides=(1, 1), \n",
    "                     padding=\"valid\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Flatten the data for Fully-connected layers. Does not affect the batch size.\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Fully-connected layers\n",
    "\n",
    "    # Dense Layer 1\n",
    "    model.add(Dense(units=1024)) # 512\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Dense Layer 2\n",
    "    model.add(Dense(units=256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    # Before training we need to configure the learning process.\n",
    "    adam_opt = Nadam(lr=0.0001, epsilon=1e-8)\n",
    "    model.compile(optimizer=adam_opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "# Prints a summary representation of your model.\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "scores = {'loss':[], 'acc':[]}\n",
    "for fold_n, (train, test) in enumerate(kfold.split(x_train, y_train)):\n",
    "    print(\"FOLD number: \", fold_n)\n",
    "    model = build_model()\n",
    "    \n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=15, verbose=1, epsilon=1e-4, mode='min')\n",
    "    \n",
    "    model.fit(x_train[train], y_train[train], \n",
    "              epochs=100,\n",
    "              verbose=2,\n",
    "              batch_size=24,\n",
    "              validation_data=(x_train[test], y_train[test]),\n",
    "              callbacks=[reduce_lr_loss])\n",
    "    \n",
    "    score = model.evaluate(x_train[test], y_train[test], verbose=1)\n",
    "    print('\\n Val score:', score[0])\n",
    "    print('\\n Val accuracy:', score[1])\n",
    "    scores['loss'].append(score[0])\n",
    "    scores['acc'].append(score[1])\n",
    "    \n",
    "print('Mean loss:', np.array(scores['loss']).mean())\n",
    "print('Mean acc:', np.array(scores['acc']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report\n",
    "# Mean loss: 0.23750277354\n",
    "# Mean acc: 0.907542492985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './saved_model/weights-Epoch{epoch:02d}-ValLoss{val_loss:.4f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', save_best_only=True, mode='max')\n",
    "#earlystop = EarlyStopping(monitor='val_loss', patience=20)\n",
    "callback = [checkpoint]#, earlystop]\n",
    "\n",
    "model_history = model.fit(x_train, y_train, \n",
    "                          epochs=20,\n",
    "                          verbose=2,\n",
    "                          batch_size=32,\n",
    "                          validation_data=(x_valid, y_valid),\n",
    "                          callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = pd.DataFrame(model_history.history)\n",
    "ax = model_history.plot(y=['val_loss','loss'])\n",
    "model_history.plot(y=['val_acc','acc'], ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "    \n",
    "Heavily overfitting\n",
    "- reduced number of total params:\n",
    "\n",
    "    - 560,450 filters 64\n",
    "    - 3,566,850 no 4th conv\n",
    "    - 1,175,042 filters 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_valid, y_onehot_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_proba(x_valid)\n",
    "\n",
    "#correct_predictions = np.argmax(preds, axis=1) == y_valid\n",
    "is_iceberg = [1 if p > 0.55 else 0 for p in preds]\n",
    "\n",
    "correct_predictions = is_iceberg == y_valid\n",
    "\n",
    "wrong = np.where(correct_predictions==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = 54\n",
    "plt.imshow(np.squeeze(x_valid[im]))\n",
    "print('label', y_valid[im])\n",
    "print('score', preds[im])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = 'saved_model'\n",
    "best = 'weights-Epoch12-ValLoss0.2140.hdf5'\n",
    "model.load_weights(filepath=os.path.join(MODEL_DIR, best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/'\n",
    "print('Predicting and writing submission for test data...')\n",
    "X = DataLoader.load_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band1 = np.asarray(X[\"band_1\"].tolist()).reshape(-1, 75,75)\n",
    "band1 = band1[:,:,:,np.newaxis]\n",
    "band1 = prep.scaler.transform(band1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band2 = np.asarray(X[\"band_2\"].tolist()).reshape(-1, 75,75)\n",
    "band2 = band2[:,:,:,np.newaxis]\n",
    "band2 = prep.scaler.transform(band2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band1_preds = model.predict_proba(band1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band2_preds = model.predict_proba(band2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_concat = pd.DataFrame({'b1':np.squeeze(band1_preds), 'b2':np.squeeze(band2_preds)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_concat['mean'] = pred_concat.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'id': X['id'], 'is_iceberg': pred_concat['mean']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = pd.DataFrame({'id': X['id'], 'is_iceberg': out[:, 1]})\n",
    "results.to_csv(os.path.join(DATA_DIR, 'submission.csv'), index=False)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
