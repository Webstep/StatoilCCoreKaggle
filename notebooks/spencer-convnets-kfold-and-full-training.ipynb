{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building CNN using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "# Local imports\n",
    "import adjust_path  # Before doing any local imports\n",
    "from icc.data_loader import DataLoader\n",
    "from icc.contrib.preprocessing.utils import *\n",
    "import icc.models.spencer.convnets_base as nets\n",
    "from icc.models.convnets_playground import ConvnetsBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = DataLoader.load_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research bench: only run if you are still experimenting with your networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold_training(init_model, X, y, k: int=5, epochs: int=100, seed: int=0):\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=15, verbose=1, \n",
    "                                           epsilon=1e-4, mode='min')\n",
    "    skfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "\n",
    "    scores = {'loss':[], 'acc':[]}\n",
    "    for fold_nr, (train, validate) in enumerate(skfold.split(X, y)):\n",
    "        print('=> Fold: {}'.format(fold_nr))\n",
    "        \n",
    "        model = init_model()\n",
    "        model.fit(X[train], y[train], \n",
    "                  epochs=epochs,\n",
    "                  verbose=2,\n",
    "                  batch_size=24,\n",
    "                  validation_data=(X[validate], y[validate]),\n",
    "                  callbacks=[reduce_lr_loss])\n",
    "\n",
    "        score = model.evaluate(X[validate], y[validate], verbose=1)\n",
    "        print('\\n')\n",
    "        print('Val score:', score[0])\n",
    "        print('Val accuracy:', score[1])\n",
    "        print('\\n')\n",
    "        scores['loss'].append(score[0])\n",
    "        scores['acc'].append(score[1])\n",
    "\n",
    "    return (scores, model)\n",
    "\n",
    "\n",
    "def model_performance(y_true, y_pred, scores):\n",
    "    metrics = {}\n",
    "    metrics['mean_loss'] = np.array(scores['loss']).mean()\n",
    "    metrics['mean_acc'] = np.array(scores['acc']).mean()\n",
    "    metrics['stdev_loss'] = np.array(scores['loss']).std()\n",
    "    metrics['stdev_acc'] = np.array(scores['acc']).std()\n",
    "    metrics['f1score'] = f1_score(y_true, y_pred)\n",
    "    metrics['rocaucscore'] = roc_auc_score(y_true, y_pred)\n",
    "    \n",
    "    print('Mean loss: {:.3f}'.format(metrics['mean_loss']))\n",
    "    print('Mean acc: {:.3f}'.format(metrics['mean_acc']))\n",
    "    print('Stdev loss: {:.3f}'.format(metrics['stdev_loss']))\n",
    "    print('Stdev acc: {:.3f}'.format(metrics['stdev_acc']))\n",
    "    print('f1 score: {:.3f}'.format(metrics['f1score']))\n",
    "    print('roc & auc score: {:.3f}'.format(metrics['rocaucscore']))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = Preprocess()\n",
    "X_filt, y_filt = prep.filter_angle(X, y)\n",
    "Xtrain, Xtest, Ytrain, Ytest = prep._basic_trainset(X_filt, y_filt, how='deep', test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run for testing out experiments and not actually fitting a model you will save the weights to.\n",
    "scores, model = run_kfold_training(nets.convnetBlue, Xtrain, Ytrain, k=2)\n",
    "\n",
    "probs = model.predict_proba(Xtest)\n",
    "Ypreds = [1 if p >= 0.5 else 0 for p in probs]\n",
    "\n",
    "model_metrics = model_performance(Ytest, Ypreds, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Satisfied with your findings, then proceed to the actual training which will be used on the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = ConvnetsBox(nets.convnetBlue, epochs=100, wdir='./saved_model/results/test')\n",
    "final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not sure what to do from here with the stacking classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save graph in case you decided to clear all. This will allow you to rebuild the graph and reload your favorite weights.\n",
    "model = nets.convnetBlue()\n",
    "save_graph_layout(model, 'blue-model-blueprint.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the graph again\n",
    "model = load_graph_layout('blue-model-blueprint.json')\n",
    "\n",
    "# Loading favorite weights.\n",
    "wdir = 'path/to/weights'\n",
    "best = 'weights-VAcc0.9257-TrAcc0.9992-VLoss0.3768-Ep39.hdf5'\n",
    "model.load_weights(filepath=os.path.join(wdir, best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare stacking submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdir = './saved_model/results/submissions/'\n",
    "stacked_1 = pd.read_csv(wdir + 'subm-blue-bestLoss_0.249-bestAcc_0.912.csv')\n",
    "stacked_2 = pd.read_csv(wdir + 'subm-white-bestLoss_0.377-bestAcc_0.926.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_subm = pd.concat([stacked_1, stacked_2['is_iceberg']], axis=1)\n",
    "cols = list(map(lambda x: \"is_iceberg_\" + str(x), range(len(concat_subm.columns[1:]))))\n",
    "concat_subm.columns = ['id'] + cols\n",
    "concat_subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking correlation\n",
    "concat_sub.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
