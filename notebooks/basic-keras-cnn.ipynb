{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building CNN using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Conv2D # spatial convolution over images\n",
    "from keras.layers import MaxPooling2D # operation for spatial data\n",
    "from keras.layers import Dense # densely-connected NN layer\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Local imports\n",
    "import adjust_path  # Before doing any local imports\n",
    "from icc.data_loader import DataLoader\n",
    "from icc.models.alexnet_model import AlexNet\n",
    "from icc.models.spencer.alexnet.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for model\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by defining a Sequential model.\n",
    "model = Sequential()\n",
    "\n",
    "# Next add layers via the `.add()` method\n",
    "\n",
    "# Conv Layer 1\n",
    "model.add(Conv2D(filters=64, \n",
    "                 kernel_size=(3, 3), \n",
    "                 strides=(1, 1), \n",
    "                 padding=\"valid\", \n",
    "                 input_shape=(75, 75, 3),\n",
    "                 kernel_initializer=\"glorot_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "# Conv Layer 2\n",
    "model.add(Conv2D(filters=128, \n",
    "                 kernel_size=(3, 3), \n",
    "                 strides=(1, 1), \n",
    "                 padding=\"valid\", \n",
    "                 kernel_initializer=\"glorot_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Conv Layer 2\n",
    "model.add(Conv2D(filters=128, \n",
    "                 kernel_size=(3, 3), \n",
    "                 strides=(1, 1), \n",
    "                 padding=\"valid\", \n",
    "                 kernel_initializer=\"glorot_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "# Conv Layer 1\n",
    "model.add(Conv2D(filters=64, \n",
    "                 kernel_size=(3, 3), \n",
    "                 strides=(1, 1), \n",
    "                 padding=\"valid\", \n",
    "                 kernel_initializer=\"glorot_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Flatten the data for Fully-connected layers. Does not affect the batch size.\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully-connected layers\n",
    "\n",
    "# Dense Layer 1\n",
    "model.add(Dense(units=512))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Dense Layer 1\n",
    "model.add(Dense(units=256))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Before training we need to configure the learning process.\n",
    "adam_opt = Adam(lr=learning_rate, epsilon=1e-8)\n",
    "model.compile(optimizer=adam_opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Prints a summary representation of your model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual training of the network\n",
    "\n",
    "# Load data\n",
    "X, y = DataLoader.load_train()\n",
    "print(\"{} samples in X and y\".format(len(X)))\n",
    "\n",
    "# Preprocessing step\n",
    "prep = Preprocess()\n",
    "x_train, x_valid, y_train, y_valid = prep._basic_trainset(X, y)\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "y_onehot_train= to_categorical(y_train, num_classes=2)\n",
    "y_onehot_valid= to_categorical(y_valid, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "filepath = 'weights.EPOCH{epoch:02d}-VAL_LOSS{val_loss:.2f}.hdf5'\n",
    "callbacks = ModelCheckpoint(filepath, monitor='val_acc', save_best_only=True, mode='auto', period=10)\n",
    "\n",
    "model_history = model.fit(x_train, \n",
    "          y_onehot_train, \n",
    "          epochs=50, \n",
    "          verbose=2, \n",
    "          batch_size=24, \n",
    "          validation_data=(x_valid, y_onehot_valid), \n",
    "          callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_valid, y_onehot_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_proba(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = 'weights.EPOCH30-VAL_LOSS0.51.hdf5'\n",
    "model.load_weights(filepath=best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_valid, y_onehot_valid)\n",
    "print('{} = {}'.format(model.metrics_names[0], score[0]))\n",
    "print('{} = {}'.format(model.metrics_names[1], score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
